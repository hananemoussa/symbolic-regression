cluster:
  scratch_path: $PFSDIR
  use_tgi: 0
  use_vllm: 1
task:
  task_name: bin
  function_str_to_extract: priority
  Weibull: 0
  OR: 1
  init_best_fit: 1
  failed_score: -20000
  timeout_period: 60
  mem_limit_gb: 10
  programdatabaseConfig:
    temp: 40.0
  initial_percentile: 0.3
model:
  model_name: llama32
  temperature: 0.9
  topk: 100
  topp: 0.95
  max_tokens: 2048
train:
  train_method_name: dpo
  finetuning_frequency: 400
  dpo_strategy: 2
  dpo_config:
    beta: 0.4
    max_seq_length: 6500
    per_device_train_batch_size: 2
    gradient_accumulation_steps: 16
    gradient_checkpointing: 1
    num_train_epochs: 2
    learning_rate: 1.0e-05
    lr_scheduler_type: cosine
    weight_decay: 0.001
    warmup_steps: 0
    logging_steps: 1
    f_divergence_type: alpha_divergence
    f_alpha_divergence_coef: 1.0
multiple_models: 0
creative_prompt: 1
descending_order: 1
gpu_nums: 0
flash_attn: 0
programdatabaseConfig:
  functions_per_prompt: 2
  num_islands: 6
  temp_sampling_flag: 1
  temp: 40.0
initial_percentile: 0.6
final_percentile: 0.2
num_cont_rounds: 50
num_outputs_per_prompt: 8
num_workers: 12
num_rounds: 2701
finetuning_frequency: 10
lr_annealing: 0
one_tuning: 0
percentile: 70
max_loops: 5
accelerate_config: 1gpu_0
lora_config:
  r: 64
  lora_alpha: 32
eval_frequency: 100
evalset: trainperturbedset
testset: testset
top_k_functions_for_test: 50
function_str_to_extract: priority
wandb_name: test_run/bin_llama32_dpo_0
group_name: test_run/bin_llama32_dpo
logs_path: .
logs_dir: out/logs/test_run/bin_bin_llama32_dpo_0
wandb: 1
project: evotune-reproducing
entity: hananenmoussa
seed: 0
run_identifier_name: bin_llama32_dpo
prefix: test_run
run_or_dev: run
use_tgi: 0
use_vllm: 1
full_accelerate_config: ./configs/accelerate_config/1gpu_0.yaml
full_model_name: meta-llama/Llama-3.2-1B-Instruct
model_dtype: bfloat16
model_adapter_dir: out/logs/test_run/bin_bin_llama32_dpo_0/model_adapter_llama32
default_wandb_name: 1v4snkna
